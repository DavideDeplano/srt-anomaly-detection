"""
Dataset management class.

Handles:
- loading and packaging of synthetic cadence data;
- loading, cropping, and packaging of real PNG waterfall plots
  into Candidate objects for downstream analysis.
"""

from pathlib import Path
import re
import logging
from typing import List, Dict, Any, Tuple
import numpy as np
from PIL import Image
import csv
from sklearn.preprocessing import SplineTransformer
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from .candidate import Candidate

try:
    from tqdm.auto import tqdm
except ImportError:
    tqdm = None

class Dataset:
    """
    Dataset wrapper.

    Responsibilities:
      - Load real PNG observations and convert them into Candidate objects.
      - Load synthetic cadences (NumPy tensors + CSV metadata) generated by
        the Setigen-based simulation script.
    """

    def __init__(self, png_dir: str | Path | None = None, use_tqdm: bool = False) -> None:
        """
        Args:
            png_dir:
                Root directory containing raw PNG waterfall plots.
                Defaults to "data/SRT_dataset".
            use_tqdm:
                If True, use tqdm progress bars when iterating files.
        """
        self._png_dir = Path(png_dir) if png_dir is not None else (Path("data") / "SRT_dataset")
        self._logger = logging.getLogger("srtad.dataset")
        self._use_tqdm = True

        # Regex pattern to parse metadata from filenames
        self._rx = re.compile(
            r'^(?P<target>[A-Za-z0-9_+-]+)-(?:ON|OFF)'
            r'_dr_(?P<dr>[-+0-9.eE]+)_freq_(?P<freq>[-+0-9.eE]+)'
            r'_f(?P<f>\d+)\.png$',
            re.IGNORECASE,
        )

    # ------------------------------------------------------------------ #
    # Synthetic cadences loader
    # ------------------------------------------------------------------ #
    def load_simulated_cadences(
        self,
        cadences_dir: Path | str,
    ) -> List[Tuple[str, np.ndarray, Dict[str, Any]]]:
        """
        Load synthetic cadences (6×H×W tensors) generated by the external
        script `scripts/generate_simulated_cadences.py`.

        Expected directory structure:

            cadences_dir/
                cadences_log.csv
                pattern00_idx00000.npy
                pattern00_idx00001.npy
                ...
                pattern63_idx00049.npy

        Returns:
            List of tuples (cadence_id, tensor, metadata_dict), where:
                - cadence_id: e.g. "pattern03_idx00042"
                - tensor: np.ndarray with shape (6, H, W)
                - metadata_dict: aggregated metadata from cadences_log.csv:
                    - pattern_id, sample_idx
                    - panels: list[dict] with per-slot ON/OFF and signal params
        """
        cadences_dir = Path(cadences_dir)
        log_path = cadences_dir / "cadences_log.csv"

        if not log_path.exists():
            raise FileNotFoundError(f"cadences_log.csv not found in {cadences_dir}")

        self._logger.info("Loading synthetic cadences from %s", cadences_dir)

        # Index: cadence_id -> dict with pattern/sample + panel list
        metadata_index: Dict[str, Dict[str, Any]] = {}

        with open(log_path, "r", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                cadence_base = row["cadence_id"]              
                pattern_id = int(row["pattern_id"])           
                cid = f"{cadence_base}_pattern{pattern_id:02d}"  

                if cid not in metadata_index:
                    metadata_index[cid] = {
                        "pattern_id": pattern_id,
                        "panels": [],
                    }

                metadata_index[cid]["panels"].append(
                    {
                        "slot": int(row["slot"]),
                        "on": bool(int(row["on"])),
                        "amplitude_factor": float(row["amplitude_factor"]),
                        "drift_rate_hz_s": float(row["drift_rate_hz_s"]),
                        "width_hz": float(row["width_hz"]),
                        "f_start_mhz": float(row["f_start_mhz"]),
                        "f_start_idx": int(row["f_start_idx"]),
                        "tchans": int(row["tchans"]),
                        "fchans": int(row["fchans"]),
                        "df_hz": float(row["df_hz"]),
                        "dt_s": float(row["dt_s"]),
                        "fch1_mhz": float(row["fch1_mhz"]),
                        "noise_mean": float(row["noise_mean"]),
                        "noise_type": row["noise_type"],
                        "random_seed": int(row["random_seed"]),
                    }
                )

        cadences: List[Tuple[str, np.ndarray, Dict[str, Any]]] = []

        # Iterate over cadences and load their tensors
        cid_iter = metadata_index.items()
        if self._use_tqdm and tqdm is not None:
            cid_iter = tqdm(cid_iter, desc="Loading synthetic cadence tensors")

        for cadence_id, meta in cid_iter:
            tensor_path = cadences_dir / f"{cadence_id}.npy"
            if not tensor_path.exists():
                raise FileNotFoundError(f"Missing cadence tensor: {tensor_path}")

            tensor = np.load(tensor_path)  # shape (6, H, W)
            cadences.append((cadence_id, tensor, meta))

        self._logger.info("Loaded %d synthetic cadences from %s", len(cadences), cadences_dir)
        return cadences

    # ------------------------------------------------------------------ #
    # Crop & real PNG loader
    # ------------------------------------------------------------------ #
    def _crop_box(self, w: int, h: int) -> tuple[int, int, int, int]:
        """
        Define the crop area as fixed fractions of image width/height.

        The goal is to remove color bars, labels, and axes while keeping
        the core signal region.
        """
        return (
            int(w * 0.0894),        # left margin
            int(h * 0.044),         # top margin
            int(w * (1 - 0.149)),   # right margin
            int(h * (1 - 0.067)),   # bottom margin
        )
    
    # ------------------------------------------------------------------ #
    # Candidates preprocessing 
    # ------------------------------------------------------------------ #
    
    def _preprocess_spectrogram(self, data: np.ndarray) -> np.ndarray:
        """
        Applies normalization and cleaning steps as per Pardo et al. (2025).
        Using Scikit-Learn for B-spline interpolation.
        
        Steps:
        1. Time-normalization: Divide flux by the mean over the observing window.
        2. DC Spike removal: Replace center channel with neighbor average.
        3. Bandpass correction: Divide by B-spline interpolation (via scikit-learn).
        """
        # Avoid division by zero
        data = np.maximum(data, 1e-9)

        # Time Normalization
        time_means = np.mean(data, axis=1, keepdims=True)
        data = data / time_means

        # DC Spike Removal (Cleaning) 
        # Assume the DC spike is at the center of the band (index W//2)
        H, W = data.shape
        dc_index = W // 2
        if 0 < dc_index < W - 1:
            # Replace the central column with the average of the two adjacent ones
            data[:, dc_index] = (data[:, dc_index - 1] + data[:, dc_index + 1]) / 2.0

        #Bandpass Correction (B-spline via Scikit-Learn) 
        # Compute the mean profile (integrated bandpass)
        bandpass = np.mean(data, axis=0)
        
        # Prepare data for sklearn (requires shape [n_samples, n_features])
        X = np.arange(len(bandpass)).reshape(-1, 1)
        y = bandpass

        try:
            # Create a pipeline: B-spline transformation -> Ridge Regression
            # n_knots controls "smoothness". A low value (e.g., 10-20) avoids overfitting to peaks.
            model = make_pipeline(
                SplineTransformer(n_knots=20, degree=3, include_bias=False),
                Ridge(alpha=1.0)
            )
            model.fit(X, y)
            smooth_bandpass = model.predict(X)

            # Divide each row by the spline profile
            # reshape(1, -1) allows broadcasting over (Time, Freq)
            data = data / smooth_bandpass.reshape(1, -1)

        except Exception as e:
            self._logger.warning(f"Scikit-learn B-spline fitting failed: {e}")

        return data
    
    # ------------------------------------------------------------------ #
    # Candidates loader
    # ------------------------------------------------------------------ #

    def load(self) -> List[Candidate]:
        """
        Scan the PNG dataset directory, load images, preprocess them,
        and return a list of Candidate objects.

        Each candidate contains:
        - metadata parsed from the filename
        - a full cadence array of shape (6, H, W) in grayscale
        """
        if not self._png_dir.exists():
            self._logger.warning("Data path not found: %s", self._png_dir)
            return []

        candidates: List[Candidate] = []

        png_iter = sorted(self._png_dir.glob("*.png"))
        if self._use_tqdm and tqdm is not None:
            png_iter = tqdm(png_iter, desc="Loading real PNG candidates")

        for png in png_iter:
            match = self._rx.match(png.name)
            if not match:
                # Filename does not match the expected pattern, skip
                self._logger.debug("Skipping file with unexpected name: %s", png.name)
                continue

            # --- Parse metadata from filename ---
            target = match.group("target")
            drift_hz_s = float(match.group("dr"))
            freq_hz = float(match.group("freq")) * 1e6  # MHz -> Hz
            f_idx = int(match.group("f"))

            # --- Notch Filter ---
            if (1.2e9 <= freq_hz <= 1.33e9) or (2.3e9 <= freq_hz <= 2.36e9):
                self._logger.debug("Skipping candidate in notch filter range: %s MHz", freq_hz)
                continue

            # --- Load image, convert to grayscale, and crop borders ---
            try:
                with Image.open(png) as im:
                    im = im.convert("L")  # grayscale: (H, W)
                    w, h = im.size
                    cropped = im.crop(self._crop_box(w, h))
                    arr = np.asarray(cropped, dtype=np.float64)
                    arr = self._preprocess_spectrogram(arr)
            except Exception as exc:
                self._logger.error("Failed to load or process image %s: %s", png, exc)
                continue

            # --- Split vertically into 6 panels (ON/OFF cadence blocks) ---
            H = arr.shape[0]
            step = H // 6
            if step == 0:
                self._logger.warning(
                    "Image too small to split into 6 panels: %s (H=%d)", png, H
                )
                continue

            panels = [arr[i * step:(i + 1) * step, :] for i in range(6)]

            # Align panel heights to the minimum height to avoid shape mismatches
            min_h = min(p.shape[0] for p in panels)
            panels = [p[:min_h, :] for p in panels]

            # --- Assemble full cadence (6, H, W) ---
            try:
                cadence = np.stack(panels, axis=0)  # shape: (6, H, W)
            except ValueError as exc:
                self._logger.error(
                    "Failed to stack panels into cadence for %s: %s", png, exc
                )
                continue

            # --- Create Candidate object ---
            candidate_id = (
                f"{target}_f{f_idx}_freq{int(freq_hz)}_dr{drift_hz_s:+.2f}"
            )

            candidate = Candidate(
                id=candidate_id,
                frequency_hz=freq_hz,
                drift_hz_s=drift_hz_s,
                cadence=cadence,
                source_path=png,
            )
            candidates.append(candidate)

        self._logger.info("Loaded %d real PNG candidates from %s", len(candidates), self._png_dir)
        return candidates


        